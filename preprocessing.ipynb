{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S95JKkcIE6wM"
      },
      "outputs": [],
      "source": [
        " #masukan modul yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#masukan data kembali yang akan diproses\n",
        "def load_data():\n",
        "    data_content = pd.read_csv('threads.csv')\n",
        "    return data_content\n",
        "\n",
        "df = load_data()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RuLOS5lqHBwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning\n",
        "def cleaning(content):\n",
        "    content = re.sub(r'\\$\\w*', '', str(content))         #digunakan untuk menghapus semua kata yang dimulai dengan tanda dolar ($) dan diikuti oleh karakter huruf, angka, atau garis bawah.      #\n",
        "    content = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', content)     #untuk menghapus semua URL atau tautan web dari teks.\n",
        "    content = re.sub('&quot;',\" \", content)         #Digunakan untuk menggantikan setiap kemunculan `&quot;` dengan spasi kosong dalam kolom `text`.\n",
        "    content = re.sub(r\"\\d+\", \" \", str(content))         #digunakan untuk menggantikan semua angka dalam teks yang disimpan dalam kolom `text` dengan spasi kosong.\n",
        "    content = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", str(content))     #digunakan untuk menghapus semua kata tunggal dalam teks yang disimpan dalam kolom `text`.\n",
        "    content = re.sub(r\"[^\\w\\s]\", \" \", str(content))         #digunakan untuk menggantikan semua karakter non-alphanumerik dan non-spasi dalam teks yang disimpan dalam variabel `content` dengan spasi kosong.\n",
        "    content = re.sub(r'(.)\\1+', r'\\1\\1', content)         #Digunakan untuk mengganti dua atau lebih karakter berulang dalam teks dengan hanya dua karakter yang berulang. Misalnya, jika terdapat karakter berulang \"eeeee\" dalam teks, maka akan digantikan dengan \"ee\".\n",
        "    content = re.sub(r\"\\s+\", \" \", str(content))       #digunakan untuk menggantikan satu atau lebih spasi berturut-turut dalam teks\n",
        "    content = re.sub(r'#', '', content)         #digunakan untuk menghapus semua tanda pagar (#) dalam teks\n",
        "    content = re.sub(r'[^a-zA-z0-9]', ' ', str(content))    #Digunakan untuk menggantikan semua karakter non-alphanumerik dalam teks dengan spasi kosong, sehingga menghapus karakter-karakter tersebut dari teks dan mempertahankan hanya huruf (kapital dan kecil) serta angka.\n",
        "    content = re.sub(r'\\b\\w{1,2}\\b', '', content)     #digunakan untuk menghapus kata-kata dengan panjang satu atau dua karakter dalam teks\n",
        "    content = re.sub(r'\\s\\s+', ' ', content)      #Digunakan untuk menggantikan dua atau lebih spasi berturut-turut dalam teks dengan satu spasi tunggal.\n",
        "    content = re.sub(r'^RT[\\s]+', '', content)        #menghapus RT\n",
        "    content = re.sub(r'^b[\\s]+', '', content)       #digunakan untuk menghapus spasi di awal teks\n",
        "    content = re.sub(r'^link[\\s]+', '', content)      #digunakan untuk menghapus string \"link\" yang diikuti oleh spasi di awal teks\n",
        "    return content\n",
        "\n",
        "def remove_emoji(content):\n",
        "    emoji = re.compile(\"[\"\n",
        "                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                        u\"\\U0001F300-\\U0001F5FF\"  # simbol & piktogram\n",
        "                        u\"\\U0001F680-\\U0001F6FF\"  # transportasi & simbol peralatan\n",
        "                        u\"\\U0001F1E0-\\U0001F1FF\"  # bendera negara\n",
        "                        u\"\\U00002702-\\U000027B0\"  # simbol\n",
        "                        u\"\\U000024C2-\\U0001F251\"  # emoji lainnya\n",
        "                        \"]+\", flags=re.UNICODE)\n",
        "    return emoji.sub(r'', content)\n",
        "\n",
        "df['cleaning'] = df['content'].apply(cleaning)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9G4ZQeFsHThV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#case folding - ubah jadi huruf kecil\n",
        "df['case_folding'] = df['cleaning'].str.lower()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EpHPvzMIHpz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenisasi - membagi kalimat jadi perkata (dipisah)\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def word_tokenize_wrapper(content):\n",
        "    return word_tokenize(content)\n",
        "\n",
        "df['tokenisasi'] = df['case_folding'].apply(lambda x: word_tokenize_wrapper(x.lower()))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "rqa52ZG8IKNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalisasi-menormalisasikan kata yang non formal menjadi formal sesuai dengan kamus colloquial-indonesian-lexicon\n",
        "def normalization (content):\n",
        "  content_slang = pd.read_csv('colloquial-indonesian-lexicon.csv')\n",
        "  dict_slang ={}\n",
        "  for i in range(content_slang.shape[0]):\n",
        "    dict_slang[content_slang[\"slang\"][i]]=content_slang[\"formal\"][i]\n",
        "\n",
        "  drop_slang = []\n",
        "  for teks in content:\n",
        "    normalisasi_teks = [dict_slang[word] if word in dict_slang.keys() else word for word in teks]\n",
        "    drop_slang.append(normalisasi_teks)\n",
        "\n",
        "  return drop_slang\n",
        "\n",
        "df['normalisasi'] = normalization(df['tokenisasi'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dD5Wu1EtJlkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stopword removal - menghapus kata sesuai dengan kamus indonesia\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "list_stopwords = stopwords.words('indonesian')\n",
        "\n",
        "#tambahan kata\n",
        "list_stopwords.extend(['yg', 'dg', 'rt', 'dgn', 'ny', 'gt', 'klo',\n",
        "                       'kalo', 'amp', 'biar', 'xad', 'xef',\n",
        "                       'gak', 'xbc', 'krn', 'nya', 'nih', 'sih',\n",
        "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya',\n",
        "                       'jd', 'jgn', 'sdh', 'xae', 'n', 't',\n",
        "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
        "                       '&', 'yah', 'no', 'je', 'xbb', 'xb', 'sch',\n",
        "                       'injirrr', 'ah', 'oena', 'bu', 'eh', 'xac', 'anjir'])\n",
        "\n",
        "list_stopwords = set(list_stopwords)\n",
        "\n",
        "def stopwords_removal(content):\n",
        "  return [word for word in content if word not in list_stopwords]\n",
        "\n",
        "df['stopword_removal'] = df['normalisasi'].apply(stopwords_removal)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ZIY7ixRaKRsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming - menghapus imbuhan\n",
        "!pip install swifter\n",
        "!pip install Sastrawi\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "import swifter\n",
        "\n",
        "#buat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "#stemmed wrapper\n",
        "def stemmed_wrapper(term):\n",
        "  return stemmer.stem(term)\n",
        "\n",
        "term_dict = {}\n",
        "\n",
        "for content in df['stopword_removal']:\n",
        "    for term in content:\n",
        "        if term not in term_dict:\n",
        "            term_dict[term] = ' '\n",
        "\n",
        "print(len(term_dict))\n",
        "print(\"------------------------\")\n",
        "\n",
        "for term in term_dict:\n",
        "    term_dict[term] = stemmed_wrapper(term)\n",
        "    print(term,\":\" ,term_dict[term])\n",
        "\n",
        "print(term_dict)\n",
        "print(\"------------------------\")\n",
        "\n",
        "#memmulai stemming\n",
        "def apply_stemmed_term(full_text):\n",
        "  return [term_dict[term] for term in full_text]\n",
        "\n",
        "df['stemming'] = df['stopword_removal'].swifter.apply(apply_stemmed_term)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jTSxkJIPXLno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#buat stemming bebas dari kurung siku\n",
        "stemming = df[['stemming']]\n",
        "\n",
        "def fit_stemming(content):\n",
        "    content = np.array(content)\n",
        "    content = ' '.join(content)\n",
        "\n",
        "    return content\n",
        "\n",
        "df['stemming'] = df['stemming'].apply(lambda x: fit_stemming(x))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_Zpwh_M9cF9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#remove kalimat duplikat dari kolom stemming\n",
        "df.drop_duplicates(subset = \"stemming\", keep = 'first', inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "GTSSlfVQdJsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simpan kedalam csv\n",
        "df.to_csv('preprocessing.csv', sep=',', index=False)"
      ],
      "metadata": {
        "id": "b2vmWMlDdNjd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}